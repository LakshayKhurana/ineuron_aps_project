[ 2023-01-05 15:06:59,722 ] 15 root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Data Ingestion <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[ 2023-01-05 15:06:59,723 ] 22 root - INFO - Exporting collection data as dataframe
[ 2023-01-05 15:06:59,723 ] 23 root - INFO - Reading data from database: aps and collection: sensor
[ 2023-01-05 15:07:02,974 ] 25 root - INFO - Found Columns: Index(['_id', 'class', 'aa_000', 'ab_000', 'ac_000', 'ad_000', 'ae_000',
       'af_000', 'ag_000', 'ag_001',
       ...
       'ee_002', 'ee_003', 'ee_004', 'ee_005', 'ee_006', 'ee_007', 'ee_008',
       'ee_009', 'ef_000', 'eg_000'],
      dtype='object', length=172)
[ 2023-01-05 15:07:02,974 ] 27 root - INFO - Dropping _id column from the DataFrame
[ 2023-01-05 15:07:03,690 ] 31 root - INFO - Save data in the feature store
[ 2023-01-05 15:07:03,690 ] 32 root - INFO - Create feature store folder if not available
[ 2023-01-05 15:07:06,105 ] 36 root - INFO - Data successfully saved in the feature store
[ 2023-01-05 15:07:06,105 ] 39 root - INFO - Splitting the dataset into train & test sets
[ 2023-01-05 15:07:06,637 ] 43 root - INFO - creating dataset folder if it does not exists
[ 2023-01-05 15:07:08,825 ] 56 root - INFO - Data Ingestion Artifact: DataIngestionArtifact(feature_store_file_path='/config/workspace/artifacts/01052023__150659/data_ingestion/feature_store/sensor.csv', train_file_path='/config/workspace/artifacts/01052023__150659/data_ingestion/dataset/train.csv', test_file_path='/config/workspace/artifacts/01052023__150659/data_ingestion/dataset/test.csv')
[ 2023-01-05 15:07:09,220 ] 27 root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Data Validation <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[ 2023-01-05 15:07:09,221 ] 107 root - INFO - reading base dataframe
[ 2023-01-05 15:07:10,918 ] 110 root - INFO - replaced na values in the base dataframe
[ 2023-01-05 15:07:11,881 ] 54 root - INFO - selecting column name which contains null values more than 0.3
[ 2023-01-05 15:07:11,882 ] 56 root - INFO - columns to be dropped: Index(['ab_000', 'bk_000', 'bl_000', 'bm_000', 'bn_000', 'bo_000', 'bp_000',
       'bq_000', 'br_000', 'cr_000'],
      dtype='object')
[ 2023-01-05 15:07:11,993 ] 112 root - INFO - dropped null values from base dataframe
[ 2023-01-05 15:07:11,993 ] 114 root - INFO - reading train dataframe
[ 2023-01-05 15:07:12,383 ] 116 root - INFO - reading test dataframe
[ 2023-01-05 15:07:12,499 ] 54 root - INFO - selecting column name which contains null values more than 0.3
[ 2023-01-05 15:07:12,500 ] 56 root - INFO - columns to be dropped: Index(['ab_000', 'bk_000', 'bl_000', 'bm_000', 'bn_000', 'bo_000', 'bp_000',
       'bq_000', 'br_000', 'cr_000'],
      dtype='object')
[ 2023-01-05 15:07:12,506 ] 120 root - INFO - dropped null values from train dataframe
[ 2023-01-05 15:07:12,510 ] 54 root - INFO - selecting column name which contains null values more than 0.3
[ 2023-01-05 15:07:12,511 ] 56 root - INFO - columns to be dropped: Index(['ab_000', 'bk_000', 'bl_000', 'bm_000', 'bn_000', 'bo_000', 'bp_000',
       'bq_000', 'br_000', 'cr_000'],
      dtype='object')
[ 2023-01-05 15:07:12,513 ] 122 root - INFO - dropped null values from test dataframe
[ 2023-01-05 15:07:13,776 ] 129 root - INFO - checking if desired columns are present in the train dataframe
[ 2023-01-05 15:07:13,776 ] 131 root - INFO - checking if desired columns are present in the test dataframe
[ 2023-01-05 15:07:13,777 ] 135 root - INFO - Since all the columns are present in the train dataframe, therefore checking data drift in the train dataframe
[ 2023-01-05 15:07:16,804 ] 139 root - INFO - Since all the columns are present in the test dataframe, therefore checking data drift in the test dataframe
[ 2023-01-05 15:07:18,055 ] 143 root - INFO - writing report in yaml file
[ 2023-01-05 15:07:18,195 ] 148 root - INFO - returning the data validation artifact @ DataValidationArtifact(report_file_path='/config/workspace/artifacts/01052023__150659/data_validation/validation_report.yaml')
[ 2023-01-05 15:07:18,201 ] 23 root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Data Transformation <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[ 2023-01-05 15:07:18,687 ] 47 root - INFO - selecting input features for train and test dataframe
[ 2023-01-05 15:07:18,704 ] 51 root - INFO - selecting target feature for train and test dataframe
[ 2023-01-05 15:07:18,704 ] 55 root - INFO - transformation of input features
[ 2023-01-05 15:07:19,088 ] 61 root - INFO - transformation of the target feature
[ 2023-01-05 15:07:19,094 ] 67 root - INFO - balancing the dataset
[ 2023-01-05 15:07:19,094 ] 69 root - INFO - shape of the train data before resampling, Input: (28950, 170), Target: (28950,)
[ 2023-01-05 15:07:24,845 ] 71 root - INFO - shape of the test data before resampling, Input: (7238, 170), Target: (7238,)
[ 2023-01-05 15:07:25,613 ] 74 root - INFO - concatenating the input and target arr for train data
[ 2023-01-05 15:07:25,639 ] 76 root - INFO - concatenating the input and target arr for test data
[ 2023-01-05 15:07:25,645 ] 78 root - INFO - saving the nunpy array data
[ 2023-01-05 15:07:25,725 ] 82 root - INFO - saving the pipeline object
[ 2023-01-05 15:07:25,725 ] 57 root - INFO - Entered the save_object method of utils
[ 2023-01-05 15:07:25,729 ] 61 root - INFO - Exited the save_object method of utils
[ 2023-01-05 15:07:25,729 ] 84 root - INFO - saving the label encoder object
[ 2023-01-05 15:07:25,729 ] 57 root - INFO - Entered the save_object method of utils
[ 2023-01-05 15:07:25,730 ] 61 root - INFO - Exited the save_object method of utils
[ 2023-01-05 15:07:25,730 ] 87 root - INFO - preparing the data transformation artifact
[ 2023-01-05 15:07:25,730 ] 95 root - INFO - returning the data transformation artifact DataTransformationArtifact(transform_object_path='/config/workspace/artifacts/01052023__150659/data_transformation/transformer/transformer.pkl', transformed_train_path='/config/workspace/artifacts/01052023__150659/data_transformation/transformed/train.npz', transformed_test_path='/config/workspace/artifacts/01052023__150659/data_transformation/transformed/test.npz', target_encoder_path='/config/workspace/artifacts/01052023__150659/data_transformation/target_encoder/target_encoder.pkl')
[ 2023-01-05 15:07:25,732 ] 18 root - INFO - >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Model Trainer <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[ 2023-01-05 15:07:25,732 ] 44 root - INFO - Loading the train and test data stored in the numpy array
[ 2023-01-05 15:07:25,764 ] 48 root - INFO - Extracting input and target features from both train and test data
[ 2023-01-05 15:07:25,764 ] 52 root - INFO - calling the model train method
[ 2023-01-05 15:07:25,764 ] 34 root - INFO - model getting trained
[ 2023-01-05 15:07:38,548 ] 55 root - INFO - calculating the f1 score for train data
[ 2023-01-05 15:07:38,596 ] 59 root - INFO - calculating the f1 score for test data
[ 2023-01-05 15:07:38,613 ] 62 root - INFO - f1 score for train data: 0.9999821838978068 & f1 score for test data: 0.9694979568009341
[ 2023-01-05 15:07:38,614 ] 64 root - INFO - checking if the model is underfitting or not
[ 2023-01-05 15:07:38,614 ] 69 root - INFO - checking if the model is overfitting or not
[ 2023-01-05 15:07:38,614 ] 75 root - INFO - Saving mode object
[ 2023-01-05 15:07:38,614 ] 57 root - INFO - Entered the save_object method of utils
[ 2023-01-05 15:07:38,619 ] 61 root - INFO - Exited the save_object method of utils
[ 2023-01-05 15:07:38,620 ] 78 root - INFO - Prepare the model trainer artifact
[ 2023-01-05 15:07:38,620 ] 82 root - INFO - Model trainer artifact: ModelTrainerArtifact(model_path='/config/workspace/artifacts/01052023__150659/model_trainer/model/model.pkl', f1_train_score=0.9999821838978068, f1_test_score=0.9694979568009341)
